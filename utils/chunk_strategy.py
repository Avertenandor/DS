"""
–ú–æ–¥—É–ª—å: –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —á–∞–Ω–∫–æ–≤–∞–Ω–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ getLogs –∑–∞–ø—Ä–æ—Å–æ–≤
–û–ø–∏—Å–∞–Ω–∏–µ: –£–º–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —á–∞–Ω–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –ª–æ–≥–æ–≤ –∏ –∏—Å—Ç–æ—Ä–∏–∏ –æ—à–∏–±–æ–∫
–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: time, collections, statistics
–ê–≤—Ç–æ—Ä: GitHub Copilot
"""

import time
import statistics
from typing import List, Dict, Optional, Tuple, Any
from collections import deque, defaultdict
from dataclasses import dataclass
from datetime import datetime, timedelta

from utils.logger import get_logger

logger = get_logger("ChunkStrategy")


@dataclass
class ChunkResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —á–∞–Ω–∫–∞"""
    chunk_size: int
    logs_count: int
    execution_time: float
    success: bool
    error_type: Optional[str] = None
    block_range: Optional[Tuple[int, int]] = None


class AdaptiveChunkStrategy:
    """–£–º–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —á–∞–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –ª–æ–≥–æ–≤ –∏ –∏—Å—Ç–æ—Ä–∏–∏"""
    
    def __init__(self, initial_chunk_size: int = 2000, 
                 max_logs_per_request: int = 750,
                 min_chunk_size: int = 100,
                 max_chunk_size: int = 5000):
        
        self.initial_chunk_size = initial_chunk_size
        self.max_logs_per_request = max_logs_per_request
        self.min_chunk_size = min_chunk_size
        self.max_chunk_size = max_chunk_size
        
        # –ò—Å—Ç–æ—Ä–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        self.history: deque[ChunkResult] = deque(maxlen=100)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –æ—à–∏–±–æ–∫
        self.error_stats = defaultdict(int)
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.current_optimal_size = initial_chunk_size
        self.last_adjustment_time = time.time()
        self.consecutive_successes = 0
        self.consecutive_errors = 0
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        self.contract_densities = {}  # –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –ª–æ–≥–æ–≤ –ø–æ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞–º
        self.time_period_densities = {}  # –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –ø–µ—Ä–∏–æ–¥–∞–º
        
        logger.info(f"üß† AdaptiveChunkStrategy –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞:")
        logger.info(f"   Initial size: {initial_chunk_size}")
        logger.info(f"   Max logs per request: {max_logs_per_request}")
        logger.info(f"   Size range: {min_chunk_size} - {max_chunk_size}")
    
    def get_optimal_chunk_size(self, start_block: int, 
                             contract_address: Optional[str] = None,
                             estimated_period: Optional[str] = None) -> int:
        """–ü–æ–ª—É—á–∏—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        
        # –ë–∞–∑–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–µ–π –∏—Å—Ç–æ—Ä–∏–∏
        base_size = self._calculate_base_size()
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞
        contract_multiplier = self._get_contract_multiplier(contract_address)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
        period_multiplier = self._get_period_multiplier(estimated_period)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ–¥–∞–≤–Ω–∏—Ö –æ—à–∏–±–æ–∫
        error_multiplier = self._get_error_multiplier()
        
        # –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä
        optimal_size = int(base_size * contract_multiplier * period_multiplier * error_multiplier)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º
        optimal_size = max(self.min_chunk_size, min(optimal_size, self.max_chunk_size))
        
        logger.debug(f"üìä –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {optimal_size}")
        logger.debug(f"   Base: {base_size}, Contract: {contract_multiplier:.2f}")
        logger.debug(f"   Period: {period_multiplier:.2f}, Error: {error_multiplier:.2f}")
        
        return optimal_size
    
    def _calculate_base_size(self) -> int:
        """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –±–∞–∑–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏"""
        if not self.history:
            return self.initial_chunk_size
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 –ø–æ–ø—ã—Ç–æ–∫
        recent_successes = [
            result for result in list(self.history)[-20:]
            if result.success and result.logs_count > 0
        ]
        
        if not recent_successes:
            return self.initial_chunk_size
        
        # –ù–∞—Ö–æ–¥–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –ª–æ–≥–æ–≤
        densities = [result.logs_count / result.chunk_size for result in recent_successes]
        avg_density = statistics.mean(densities)
        
        if avg_density > 0:
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ª–æ–≥–æ–≤
            target_size = int(self.max_logs_per_request / avg_density)
            return max(self.min_chunk_size, min(target_size, self.max_chunk_size))
        
        return self.initial_chunk_size
    
    def _get_contract_multiplier(self, contract_address: Optional[str]) -> float:
        """–ü–æ–ª—É—á–∏—Ç—å –º–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞"""
        if not contract_address or contract_address not in self.contract_densities:
            return 1.0
        
        density = self.contract_densities[contract_address]
        
        # –ß–µ–º –≤—ã—à–µ –ø–ª–æ—Ç–Ω–æ—Å—Ç—å, —Ç–µ–º –º–µ–Ω—å—à–µ —á–∞–Ω–∫
        if density > 2.0:  # –í—ã—Å–æ–∫–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å
            return 0.3
        elif density > 1.0:  # –°—Ä–µ–¥–Ω—è—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å
            return 0.6
        elif density > 0.5:  # –ù–∏–∑–∫–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å
            return 0.8
        else:  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å
            return 1.5
    
    def _get_period_multiplier(self, estimated_period: Optional[str]) -> float:
        """–ü–æ–ª—É—á–∏—Ç—å –º–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞"""
        if not estimated_period:
            return 1.0
        
        # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã –≤—ã—Å–æ–∫–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        high_activity_periods = ['2024-11', '2024-12', '2025-01']  # –ü—Ä–∏–º–µ—Ä—ã
        
        if estimated_period in high_activity_periods:
            return 0.4  # –£–º–µ–Ω—å—à–∞–µ–º —á–∞–Ω–∫ –¥–ª—è –ø–µ—Ä–∏–æ–¥–æ–≤ –≤—ã—Å–æ–∫–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–µ—Ä–∏–æ–¥–∞
        if estimated_period in self.time_period_densities:
            density = self.time_period_densities[estimated_period]
            return max(0.2, min(2.0, 1.0 / max(0.5, density)))
        
        return 1.0
    
    def _get_error_multiplier(self) -> float:
        """–ü–æ–ª—É—á–∏—Ç—å –º–Ω–æ–∂–∏—Ç–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ–¥–∞–≤–Ω–∏—Ö –æ—à–∏–±–æ–∫"""
        if not self.history:
            return 1.0
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –ø–æ–ø—ã—Ç–æ–∫
        recent = list(self.history)[-10:]
        recent_errors = [r for r in recent if not r.success]
        
        if not recent_errors:
            # –ù–µ—Ç –Ω–µ–¥–∞–≤–Ω–∏—Ö –æ—à–∏–±–æ–∫ - –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä
            return min(1.2, 1.0 + (self.consecutive_successes * 0.05))
        
        # –ï—Å—Ç—å –æ—à–∏–±–∫–∏ - –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø
        payload_errors = sum(1 for r in recent_errors if r.error_type == 'payload_too_large')
        timeout_errors = sum(1 for r in recent_errors if r.error_type == 'timeout')
        
        if payload_errors > 0:
            # –°–µ—Ä—å–µ–∑–Ω–æ —É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö payload
            return max(0.1, 0.5 ** payload_errors)
        
        if timeout_errors > 0:
            # –£–º–µ—Ä–µ–Ω–Ω–æ —É–º–µ–Ω—å—à–∞–µ–º –ø—Ä–∏ —Ç–∞–π–º–∞—É—Ç–∞—Ö
            return max(0.3, 0.8 ** timeout_errors)
        
        # –î—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏ - –Ω–µ–±–æ–ª—å—à–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ
        return max(0.7, 1.0 - (len(recent_errors) * 0.1))
    
    def record_result(self, chunk_size: int, logs_count: int, 
                     execution_time: float, success: bool,
                     error_type: Optional[str] = None,
                     block_range: Optional[Tuple[int, int]] = None,
                     contract_address: Optional[str] = None):
        """–ó–∞–ø–∏—Å–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —á–∞–Ω–∫–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        
        result = ChunkResult(
            chunk_size=chunk_size,
            logs_count=logs_count,
            execution_time=execution_time,
            success=success,
            error_type=error_type,
            block_range=block_range
        )
        
        self.history.append(result)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏
        if success:
            self.consecutive_successes += 1
            self.consecutive_errors = 0
        else:
            self.consecutive_errors += 1
            self.consecutive_successes = 0
            self.error_stats[error_type or 'unknown'] += 1
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞
        if contract_address and success and logs_count > 0:
            density = logs_count / chunk_size
            if contract_address in self.contract_densities:
                # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
                old_density = self.contract_densities[contract_address]
                self.contract_densities[contract_address] = 0.7 * old_density + 0.3 * density
            else:
                self.contract_densities[contract_address] = density
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        status = "‚úÖ" if success else "‚ùå"
        logger.debug(f"{status} –ß–∞–Ω–∫ {chunk_size} –±–ª–æ–∫–æ–≤: {logs_count} –ª–æ–≥–æ–≤ –∑–∞ {execution_time:.2f}s")
        
        if not success:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á–∞–Ω–∫–∞: {error_type}")
    
    def handle_payload_too_large(self, current_chunk_size: int) -> int:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏ 'payload too large'"""
        # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ —É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä
        new_size = max(self.min_chunk_size, current_chunk_size // 4)
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤—ã—Å–æ–∫–æ–π –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏
        self.record_result(
            chunk_size=current_chunk_size,
            logs_count=2000,  # –ò–º–∏—Ç–∏—Ä—É–µ–º –≤—ã—Å–æ–∫—É—é –ø–ª–æ—Ç–Ω–æ—Å—Ç—å
            execution_time=0,
            success=False,
            error_type='payload_too_large'
        )
        
        logger.warning(f"üö® Payload too large! –£–º–µ–Ω—å—à–∞–µ–º —á–∞–Ω–∫: {current_chunk_size} ‚Üí {new_size}")
        return new_size
    
    def handle_timeout(self, current_chunk_size: int) -> int:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞"""
        # –£–º–µ—Ä–µ–Ω–Ω–æ —É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä
        new_size = max(self.min_chunk_size, int(current_chunk_size * 0.7))
        
        self.record_result(
            chunk_size=current_chunk_size,
            logs_count=0,
            execution_time=30.0,  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —Ç–∞–π–º–∞—É—Ç
            success=False,
            error_type='timeout'
        )
        
        logger.warning(f"‚è∞ Timeout! –£–º–µ–Ω—å—à–∞–µ–º —á–∞–Ω–∫: {current_chunk_size} ‚Üí {new_size}")
        return new_size
    
    def suggest_progressive_chunks(self, total_blocks: int, 
                                 start_block: int,
                                 contract_address: Optional[str] = None) -> List[Tuple[int, int]]:
        """–ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —á–∞–Ω–∫–æ–≤ –¥–ª—è –±–æ–ª—å—à–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞"""
        chunks = []
        current_start = start_block
        
        while current_start < start_block + total_blocks:
            # –ü–æ–ª—É—á–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è —Ç–µ–∫—É—â–µ–π –ø–æ–∑–∏—Ü–∏–∏
            chunk_size = self.get_optimal_chunk_size(
                current_start, 
                contract_address=contract_address
            )
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ü–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–∞
            chunk_end = min(current_start + chunk_size - 1, start_block + total_blocks - 1)
            
            chunks.append((current_start, chunk_end))
            current_start = chunk_end + 1
        
        logger.info(f"üìã –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –¥–ª—è {total_blocks} –±–ª–æ–∫–æ–≤")
        logger.info(f"   –†–∞–∑–º–µ—Ä—ã: {[end - start + 1 for start, end in chunks[:5]]}... (–ø–µ—Ä–≤—ã–µ 5)")
        
        return chunks
    
    def get_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —á–∞–Ω–∫–æ–≤–∞–Ω–∏—è"""
        if not self.history:
            return {'status': 'no_data'}
        
        total_requests = len(self.history)
        successful_requests = sum(1 for r in self.history if r.success)
        success_rate = (successful_requests / total_requests * 100) if total_requests > 0 else 0
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ —á–∞–Ω–∫–æ–≤
        chunk_sizes = [r.chunk_size for r in self.history if r.success]
        avg_chunk_size = statistics.mean(chunk_sizes) if chunk_sizes else 0
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        execution_times = [r.execution_time for r in self.history if r.success]
        avg_execution_time = statistics.mean(execution_times) if execution_times else 0
        
        # –ê–Ω–∞–ª–∏–∑ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –ª–æ–≥–æ–≤
        densities = [
            r.logs_count / r.chunk_size 
            for r in self.history 
            if r.success and r.chunk_size > 0
        ]
        avg_density = statistics.mean(densities) if densities else 0
        
        return {
            'total_requests': total_requests,
            'success_rate': f"{success_rate:.1f}%",
            'current_optimal_size': self.current_optimal_size,
            'avg_chunk_size': int(avg_chunk_size),
            'avg_execution_time': f"{avg_execution_time:.2f}s",
            'avg_log_density': f"{avg_density:.3f}",
            'consecutive_successes': self.consecutive_successes,
            'consecutive_errors': self.consecutive_errors,
            'error_stats': dict(self.error_stats),
            'known_contracts': len(self.contract_densities),
            'contract_densities': {
                addr: f"{density:.3f}" 
                for addr, density in list(self.contract_densities.items())[:5]
            }
        }
    
    def reset_strategy(self):
        """–°–±—Ä–æ—Å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∫ –Ω–∞—á–∞–ª—å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º"""
        self.history.clear()
        self.error_stats.clear()
        self.contract_densities.clear()
        self.time_period_densities.clear()
        self.current_optimal_size = self.initial_chunk_size
        self.consecutive_successes = 0
        self.consecutive_errors = 0
        
        logger.info("üîÑ –°—Ç—Ä–∞—Ç–µ–≥–∏—è —á–∞–Ω–∫–æ–≤–∞–Ω–∏—è —Å–±—Ä–æ—à–µ–Ω–∞ –∫ –Ω–∞—á–∞–ª—å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º")


class ProgressiveChunkManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ —á–∞–Ω–∫–æ–≤–∞–Ω–∏—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤"""
    
    def __init__(self, strategy: AdaptiveChunkStrategy):
        self.strategy = strategy
        self.current_progress = 0
        self.total_progress = 0
        self.start_time = 0
        
    def process_large_range(self, start_block: int, end_block: int,
                          fetch_func, contract_address: Optional[str] = None,
                          progress_callback=None) -> List[Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –±–ª–æ–∫–æ–≤ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º —á–∞–Ω–∫–æ–≤–∞–Ω–∏–µ–º"""
        
        total_blocks = end_block - start_block + 1
        self.total_progress = total_blocks
        self.current_progress = 0
        self.start_time = time.time()
        
        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É {total_blocks:,} –±–ª–æ–∫–æ–≤")
        logger.info(f"   –î–∏–∞–ø–∞–∑–æ–Ω: {start_block:,} - {end_block:,}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —á–∞–Ω–∫–∏
        chunks = self.strategy.suggest_progressive_chunks(
            total_blocks, start_block, contract_address
        )
        
        all_results = []
        processed_blocks = 0
        
        for i, (chunk_start, chunk_end) in enumerate(chunks):
            chunk_size = chunk_end - chunk_start + 1
            
            try:
                # –ó–∞—Å–µ–∫–∞–µ–º –≤—Ä–µ–º—è
                start_time = time.time()
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
                chunk_results = fetch_func(chunk_start, chunk_end)
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —É—Å–ø–µ—Ö
                execution_time = time.time() - start_time
                self.strategy.record_result(
                    chunk_size=chunk_size,
                    logs_count=len(chunk_results) if hasattr(chunk_results, '__len__') else 0,
                    execution_time=execution_time,
                    success=True,
                    block_range=(chunk_start, chunk_end),
                    contract_address=contract_address
                )
                
                all_results.extend(chunk_results if hasattr(chunk_results, '__iter__') else [chunk_results])
                processed_blocks += chunk_size
                self.current_progress = processed_blocks
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                if progress_callback:
                    progress_pct = (processed_blocks / total_blocks) * 100
                    elapsed = time.time() - self.start_time
                    estimated_total = (elapsed / processed_blocks) * total_blocks if processed_blocks > 0 else 0
                    remaining = max(0, estimated_total - elapsed)
                    
                    progress_callback({
                        'current': processed_blocks,
                        'total': total_blocks,
                        'percentage': progress_pct,
                        'elapsed': elapsed,
                        'estimated_remaining': remaining,
                        'chunks_completed': i + 1,
                        'total_chunks': len(chunks)
                    })
                
                logger.debug(f"‚úÖ –ß–∞–Ω–∫ {i+1}/{len(chunks)}: {chunk_size} –±–ª–æ–∫–æ–≤ –∑–∞ {execution_time:.2f}s")
                
            except Exception as e:
                error_type = self._classify_error(e)
                execution_time = time.time() - start_time
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É
                self.strategy.record_result(
                    chunk_size=chunk_size,
                    logs_count=0,
                    execution_time=execution_time,
                    success=False,
                    error_type=error_type,
                    block_range=(chunk_start, chunk_end),
                    contract_address=contract_address
                )
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏
                if error_type == 'payload_too_large':
                    logger.error(f"‚ùå Payload too large –¥–ª—è —á–∞–Ω–∫–∞ {chunk_start}-{chunk_end}")
                    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–±–∏—Ç—å —á–∞–Ω–∫ –ø–æ–ø–æ–ª–∞–º
                    if chunk_size > self.strategy.min_chunk_size * 2:
                        mid_block = (chunk_start + chunk_end) // 2
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –¥–≤–∞ –Ω–æ–≤—ã—Ö —á–∞–Ω–∫–∞ –≤ –æ—á–µ—Ä–µ–¥—å
                        chunks.insert(i + 1, (chunk_start, mid_block))
                        chunks.insert(i + 2, (mid_block + 1, chunk_end))
                        
                        logger.info(f"üîÑ –†–∞–∑–±–∏–≤–∞–µ–º —á–∞–Ω–∫ –Ω–∞ –¥–≤–∞: {chunk_start}-{mid_block}, {mid_block+1}-{chunk_end}")
                        continue
                
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —á–∞–Ω–∫–µ {chunk_start}-{chunk_end}: {e}")
                raise
        
        elapsed_total = time.time() - self.start_time
        
        logger.info(f"‚úÖ –ü—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
        logger.info(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –±–ª–æ–∫–æ–≤: {processed_blocks:,}")
        logger.info(f"   –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed_total:.1f}s")
        logger.info(f"   –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {processed_blocks/elapsed_total:.1f} –±–ª–æ–∫–æ–≤/—Å–µ–∫")
        logger.info(f"   –í—Å–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(all_results):,}")
        
        return all_results
    
    def _classify_error(self, error: Exception) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ –æ—à–∏–±–∫–∏"""
        error_str = str(error).lower()
        
        if 'payload too large' in error_str or '413' in error_str:
            return 'payload_too_large'
        elif 'timeout' in error_str or 'timed out' in error_str:
            return 'timeout'
        elif 'rate limit' in error_str or '429' in error_str:
            return 'rate_limit'
        elif 'connection' in error_str:
            return 'connection_error'
        else:
            return 'unknown'


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ AdaptiveChunkStrategy...")
    
    strategy = AdaptiveChunkStrategy()
    
    # –°–∏–º—É–ª–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–æ–≤
    test_scenarios = [
        # (chunk_size, logs_count, execution_time, success, error_type)
        (2000, 500, 1.2, True, None),  # –ù–æ—Ä–º–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        (2000, 1500, 3.5, False, 'payload_too_large'),  # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ª–æ–≥–æ–≤
        (500, 200, 0.8, True, None),  # –£–º–µ–Ω—å—à–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç
        (500, 150, 0.7, True, None),  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –º–∞–ª—ã–º —Ä–∞–∑–º–µ—Ä–æ–º
        (750, 300, 1.0, True, None),  # –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º
        (1000, 400, 1.3, True, None),  # –ï—â–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º
        (1500, 800, 2.1, True, None),  # –•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    ]
    
    for i, (chunk_size, logs_count, exec_time, success, error_type) in enumerate(test_scenarios):
        strategy.record_result(chunk_size, logs_count, exec_time, success, error_type)
        
        optimal = strategy.get_optimal_chunk_size(100000 + i * 1000)
        print(f"–ó–∞–ø—Ä–æ—Å {i+1}: –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä = {optimal}")
    
    print(f"\nüìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    stats = strategy.get_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # –¢–µ—Å—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
    print(f"\nüìã –¢–µ—Å—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã—Ö —á–∞–Ω–∫–æ–≤:")
    chunks = strategy.suggest_progressive_chunks(
        total_blocks=10000,
        start_block=50000000,
        contract_address="0x41d9650faf3341cbf8947fd8063a1fc88dbf1889"
    )
    
    print(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤:")
    for i, (start, end) in enumerate(chunks[:3]):
        print(f"  –ß–∞–Ω–∫ {i+1}: {start} - {end} ({end-start+1} –±–ª–æ–∫–æ–≤)")
    
    print("\n‚úÖ AdaptiveChunkStrategy —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
